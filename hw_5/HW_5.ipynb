{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import nessesary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from collections import OrderedDict\n",
    "from datetime import timedelta\n",
    "\n",
    "# pip install geopy #This is used to calculate distance based on lat and long... no need to reinvent the wheel...\n",
    "\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in top airport data from supplied files\n",
    "path = 'hw_5_data/'\n",
    "#db_name = 'airports2.db'\n",
    "db_name = 'airport_db'\n",
    "top_airpots = pd.read_csv(path+'top_airports.csv' )\n",
    "airport_info = pd.read_csv(path+'ICAO_airports.csv' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>Airport</th>\n",
       "      <th>Role</th>\n",
       "      <th>Enplanements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>KATL</td>\n",
       "      <td>Hartsfield-Jackson Atlanta International Airport</td>\n",
       "      <td>P-L</td>\n",
       "      <td>43130585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>ORD</td>\n",
       "      <td>ORD</td>\n",
       "      <td>KORD</td>\n",
       "      <td>Chicago O'Hare International Airport</td>\n",
       "      <td>P-L</td>\n",
       "      <td>32171831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>LAX</td>\n",
       "      <td>LAX</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>P-L</td>\n",
       "      <td>30528737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DFW</td>\n",
       "      <td>KDFW</td>\n",
       "      <td>Dallas/Fort Worth International Airport</td>\n",
       "      <td>P-L</td>\n",
       "      <td>27100656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denver</td>\n",
       "      <td>DEN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>KDEN</td>\n",
       "      <td>Denver International Airport</td>\n",
       "      <td>P-L</td>\n",
       "      <td>25241962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City  FAA IATA  ICAO  \\\n",
       "0            Atlanta  ATL  ATL  KATL   \n",
       "1            Chicago  ORD  ORD  KORD   \n",
       "2        Los Angeles  LAX  LAX  KLAX   \n",
       "3  Dallas-Fort Worth  DFW  DFW  KDFW   \n",
       "4             Denver  DEN  DEN  KDEN   \n",
       "\n",
       "                                            Airport Role  Enplanements  \n",
       "0  Hartsfield-Jackson Atlanta International Airport  P-L      43130585  \n",
       "1              Chicago O'Hare International Airport  P-L      32171831  \n",
       "2                 Los Angeles International Airport  P-L      30528737  \n",
       "3           Dallas/Fort Worth International Airport  P-L      27100656  \n",
       "4                      Denver International Airport  P-L      25241962  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "airport_info['ICAO'] = airport_info['ident']\n",
    "combined_info = top_airpots.merge(airport_info, on='ICAO')\n",
    "\n",
    "top_airpots.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make SQL tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table info already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1d81781a4972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     precipitation FLOAT)\"\"\"\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_info_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_weather_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: table info already exists"
     ]
    }
   ],
   "source": [
    "connection = sqlite3.connect(path+db_name)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#Create a table for the airport info and a table for the corresponding weather\n",
    "sql_info_cmd = \"\"\"CREATE TABLE info (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    ICAO TEXT,\n",
    "    name TEXT,\n",
    "    city TEXT,\n",
    "    latitude_deg FLOAT,\n",
    "    longitude_deg FLOAT,\n",
    "    elevation FLOAT,\n",
    "    enplanements INT)\"\"\"\n",
    "\n",
    "\n",
    "sql_weather_cmd = \"\"\"CREATE TABLE weather (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    ICAO TEXT,\n",
    "    date DATE,\n",
    "    temp_high FLOAT,\n",
    "    temp_ave FLOAT,\n",
    "    temp_low FLOAT,\n",
    "    humidity_ave FLOAT,\n",
    "    precipitation FLOAT)\"\"\"\n",
    "\n",
    "cursor.execute(sql_info_cmd)\n",
    "cursor.execute(sql_weather_cmd)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape data from weather underground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to format dates and get date range to request data\n",
    "\n",
    "def month_to_int(string):\n",
    "    month_dict ={'Jan' : 1,\n",
    "                 'Feb' : 2,\n",
    "                 'Mar' : 3,\n",
    "                 'Apr' : 4,\n",
    "                 'May' : 5,\n",
    "                 'Jun' : 6,\n",
    "                 'Jul' : 7,\n",
    "                 'Aug' : 8,\n",
    "                 'Sep' : 9,\n",
    "                 'Oct' : 10,\n",
    "                 'Nov' : 11,\n",
    "                 'Dec' : 12}\n",
    "    return month_dict[string]\n",
    "\n",
    "def month_to_str(int):\n",
    "    months =['Jan' ,'Feb' ,'Mar' ,'Apr' ,'May' ,'Jun' ,'Jul' ,'Aug' ,'Sep' ,'Oct' ,'Nov' ,'Dec' ]\n",
    "    return months[int]\n",
    "\n",
    "\n",
    "def strip_date(date):\n",
    "    date_temp = date.split('/')\n",
    "    year = date_temp[0]\n",
    "    month = date_temp[1]\n",
    "    day = date_temp[2]\n",
    "    \n",
    "    return year,month,day\n",
    "\n",
    "def inc_by_year(date):\n",
    "    '''\n",
    "    Helper function to incriment a given date by one year,\n",
    "    expects to be in format %Y/%m/%d\n",
    "    '''\n",
    "    date_temp = date.split('/')\n",
    "    year_inc = str(int(date_temp[0])+1)\n",
    "    new_date = '{}/{}/{}'.format(year_inc, date_temp[1], date_temp[2])\n",
    "    return new_date\n",
    "\n",
    "def inc_by_day(date):\n",
    "    '''\n",
    "    Helper function to incriment a given date by one day,\n",
    "    expects to be in format %Y/%m/%d\n",
    "    '''\n",
    "    date_temp = date.split('/')\n",
    "    day_inc = str(int(date_temp[2])+1)\n",
    "    new_date = '{}/{}/{}'.format(date_temp[0], date_temp[1], day_inc)\n",
    "    return new_date\n",
    "\n",
    "\n",
    "def get_date_range_to_query(date_start,date_end):\n",
    "    '''\n",
    "    Weatherunderground historical data only returns a years worth of data at a time,\n",
    "    this function takes the users defined date range, and returns a list of start and end dates divided\n",
    "    into year long chunks. \n",
    "    '''\n",
    "    if date_end == 'today':\n",
    "        today = datetime.now()\n",
    "        date_end = '{}/{}/{}'.format(today.year, today.month, today.day)\n",
    "    \n",
    "    date_range = list()\n",
    "    dates_temp_list = list()\n",
    "    \n",
    "    dates_temp_list.append(date_start)\n",
    "    \n",
    "    date_delta = (datetime.strptime(date_end, '%Y/%m/%d') - datetime.strptime(date_start, '%Y/%m/%d'))\n",
    "    date_delta_years = int(date_delta.total_seconds()/(60*60*24*365.2425))\n",
    "    \n",
    "    for iyear in range(date_delta_years):\n",
    "        temp_date = inc_by_year(dates_temp_list[iyear])\n",
    "        dates_temp_list.append(temp_date)\n",
    "        \n",
    "    lgc_first_interation = True    \n",
    "    \n",
    "    for idate in range(len(dates_temp_list)):\n",
    "        if lgc_first_interation:\n",
    "            try:\n",
    "                date_range.append([dates_temp_list[idate],dates_temp_list[idate+1]])\n",
    "            except:\n",
    "                date_range.append([dates_temp_list[idate],date_end])           \n",
    "        else:\n",
    "            try:\n",
    "                date_range.append([inc_by_day(dates_temp_list[idate]),dates_temp_list[idate+1]])\n",
    "            except:\n",
    "                date_range.append([dates_temp_list[idate],date_end])\n",
    "        lgc_first_interation = False  \n",
    "    \n",
    "    return date_range\n",
    "\n",
    "\n",
    "#get_date_range_to_query(date_start,date_end='today')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2004'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(airport_code, date_start,date_end,data_needed,data_list):\n",
    "    '''\n",
    "    This function getting the info from WU for a specified start and end date, for a given airport code.\n",
    "    'data_needed' is an ordered ditcionary that gives tells what columns of data to keep. This function expects \n",
    "    a range of dates of a year or less. This requirement will be taken care of by the program that calls it. \n",
    "    \n",
    "    '''\n",
    "    start_year, start_month, start_day = strip_date(date_start)\n",
    "    end_year, end_month, end_day = strip_date(date_end)\n",
    "    \n",
    "    month_str = month_to_str(int(start_month))\n",
    "    current_year = int(start_year)\n",
    "    current_month_temp = int(start_month)\n",
    "    \n",
    "    url = url = 'https://www.wunderground.com/history/airport/{}/{}/CustomHistory.html?dayend={}&monthend={}&yearend={}'.format(\n",
    "            airport_code, date_start, end_day, end_month, end_year)\n",
    "    \n",
    "    response = urlopen(url)\n",
    "    html = response.read()\n",
    "    response.close()\n",
    "    \n",
    "    # Use Beautiful soup \n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Grab the second table\n",
    "    table = soup.findAll('table')[1]\n",
    "    results = list()\n",
    "\n",
    "    for iline, line in enumerate(table.findAll('tr')):\n",
    "        #we need to get ignore the header. All the headers have the text 'high' 'low' 'ave' ..etc. so \n",
    "        #if we just check that one of these words is not in the line we are looking at. If it is, then we grab\n",
    "        #the month name from it, then we will skip the header\n",
    "\n",
    "        values_per_line = list()\n",
    "        if 'high' in line.text:\n",
    "            month_temp = line.text[0]\n",
    "            for ivalue, value in enumerate(line.findAll('td')):\n",
    "                if ivalue == 0:\n",
    "                    month_str = ''.join([word.rstrip() for word in value.findAll(text=True)])\n",
    "                    current_month = month_to_int(month_str)\n",
    "            #print(month_str)\n",
    "        if 'high' not in line.text:\n",
    "\n",
    "            #print(iline)    \n",
    "            #itterate through all the values in the line\n",
    "            for ivalue, value in enumerate(line.findAll('td')):\n",
    "\n",
    "                #print(value)\n",
    "                if ivalue in data_needed.values():\n",
    "                    \n",
    "                    stripped_vals = ''.join([word.rstrip() for word in value.findAll(text=True)])\n",
    "                    #print(stripped_vals)\n",
    "                    values_per_line.append(stripped_vals)\n",
    "            \n",
    "\n",
    "        if values_per_line != []: #make sure there is data in the list\n",
    "            if current_month < int(current_month_temp):\n",
    "                current_year += 1\n",
    "                current_month_temp = current_month\n",
    "            if current_month == start_month:\n",
    "                if values_per_line[0] < int(start_day):\n",
    "                    current_year += 1\n",
    "                    current_month_temp = current_month\n",
    "                    \n",
    "            temp_date =  '{}-{}-{}'.format(str(current_year),str(current_month),str(values_per_line[0]))\n",
    "            values_per_line[0] = temp_date\n",
    "            #temp_date = '{}/{}/{}'.format(start_year,start_month,values_per_line[0])\n",
    "            #values_per_line[0]\n",
    "            data_list.append(values_per_line)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def get_weather_data(airport_code,date_start,date_end):\n",
    "    \n",
    "    data_needed = OrderedDict({'date': 0, 'temp_high': 1, 'temp_ave': 2, 'temp_low': 3,\n",
    "                                    'humidity_ave': 8, 'precipitation': 19})\n",
    "    \n",
    "    date_range = get_date_range_to_query(date_start,date_end)\n",
    "    data_list = []\n",
    "    for idate in range(len(date_range)):\n",
    "        while True:\n",
    "            try:\n",
    "                scrape_data(airport_code\\\n",
    "                                   , date_range[idate][0],date_range[idate][1],data_needed,data_list)\n",
    "                break\n",
    "            except URLError:\n",
    "                print('Connection to WeatherUnderground broken')\n",
    "                pass\n",
    "        \n",
    "            \n",
    "    data_df = pd.DataFrame(data_list, columns=data_needed.keys())\n",
    "    for key in data_needed.keys():\n",
    "        if key != 'date':\n",
    "        data_df[key] = pd.to_numeric(data_df[key], errors='coerce')\n",
    "    data_df = data_df.fillna(0)\n",
    "    \n",
    "    return data_df\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "toot = get_weather_data('KSFO','2004/2/4','today')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp_high</th>\n",
       "      <th>temp_ave</th>\n",
       "      <th>temp_low</th>\n",
       "      <th>humidity_ave</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-2-4</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-2-5</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>88</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-2-6</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>84</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-2-7</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-2-8</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "      <td>73</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004-2-9</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004-2-10</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2004-2-11</td>\n",
       "      <td>61</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2004-2-12</td>\n",
       "      <td>62</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2004-2-13</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2004-2-14</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2004-2-15</td>\n",
       "      <td>61</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>87</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2004-2-16</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>89</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004-2-17</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>81</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2004-2-18</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>84</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2004-2-19</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2004-2-20</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>79</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2004-2-21</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>80</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2004-2-22</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>82</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2004-2-23</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2004-2-24</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>75</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2004-2-25</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>82</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2004-2-26</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>78</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2004-2-27</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>81</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2004-2-28</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2004-2-29</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2004-3-1</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>84</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2004-3-2</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2004-3-3</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2004-3-4</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>2018-2-10</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>2018-2-11</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123</th>\n",
       "      <td>2018-2-12</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>2018-2-13</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>2018-2-14</td>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>2018-2-15</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>2018-2-16</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>42</td>\n",
       "      <td>59</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>2018-2-17</td>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>2018-2-18</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>2018-2-19</td>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>2018-2-20</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>53</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>2018-2-21</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>53</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5133</th>\n",
       "      <td>2018-2-22</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5134</th>\n",
       "      <td>2018-2-23</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>2018-2-24</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "      <td>63</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136</th>\n",
       "      <td>2018-2-25</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5137</th>\n",
       "      <td>2018-2-26</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>2018-2-27</td>\n",
       "      <td>58</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>2018-2-28</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5140</th>\n",
       "      <td>2018-3-1</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>74</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>2018-3-2</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5142</th>\n",
       "      <td>2018-3-3</td>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>76</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>2018-3-4</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>2018-3-5</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>2018-3-6</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>2018-3-7</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>2018-3-8</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>2018-3-9</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>2018-3-10</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>2018-3-11</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5151 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date temp_high temp_ave temp_low humidity_ave precipitation\n",
       "0      2004-2-4        55       52       46           86          0.00\n",
       "1      2004-2-5        55       48       42           88          0.00\n",
       "2      2004-2-6        57       52       46           84          0.02\n",
       "3      2004-2-7        55       50       45           77          0.00\n",
       "4      2004-2-8        57       48       39           73          0.00\n",
       "5      2004-2-9        60       50       39           65          0.00\n",
       "6     2004-2-10        60       54       46           50          0.00\n",
       "7     2004-2-11        61       50       39           70          0.00\n",
       "8     2004-2-12        62       52       43           70          0.00\n",
       "9     2004-2-13        59       52       46           63          0.00\n",
       "10    2004-2-14        57       54       51           77          0.00\n",
       "11    2004-2-15        61       54       48           87          0.05\n",
       "12    2004-2-16        61       56       51           89          0.52\n",
       "13    2004-2-17        64       60       57           81          0.57\n",
       "14    2004-2-18        57       54       50           84          0.39\n",
       "15    2004-2-19        54       50       46           80          0.00\n",
       "16    2004-2-20        55       52       48           79          0.05\n",
       "17    2004-2-21        53       50       46           80          0.04\n",
       "18    2004-2-22        55       52       48           82          0.06\n",
       "19    2004-2-23        59       54       48           81          0.00\n",
       "20    2004-2-24        59       55       51           75          0.09\n",
       "21    2004-2-25        59       54       48           82          1.46\n",
       "22    2004-2-26        55       52       48           78          0.13\n",
       "23    2004-2-27        55       50       46           81          0.06\n",
       "24    2004-2-28        57       50       44           79          0.00\n",
       "25    2004-2-29        54       51       48           79          0.00\n",
       "26     2004-3-1        53       50       48           84          0.07\n",
       "27     2004-3-2        64       54       45           64          0.00\n",
       "28     2004-3-3        57       54       50           68          0.00\n",
       "29     2004-3-4        60       54       48           80          0.00\n",
       "...         ...       ...      ...      ...          ...           ...\n",
       "5121  2018-2-10        65       59       53           55          0.00\n",
       "5122  2018-2-11        63       54       44           56          0.00\n",
       "5123  2018-2-12        59       53       47           56          0.00\n",
       "5124  2018-2-13        63       56       49           40          0.00\n",
       "5125  2018-2-14        60       53       45           56          0.00\n",
       "5126  2018-2-15        64       54       44           56          0.00\n",
       "5127  2018-2-16        65       54       42           59          0.00\n",
       "5128  2018-2-17        67       56       45           66          0.00\n",
       "5129  2018-2-18        58       52       45           68          0.02\n",
       "5130  2018-2-19        53       48       43           54          0.00\n",
       "5131  2018-2-20        53       45       36           53          0.00\n",
       "5132  2018-2-21        56       49       42           53          0.00\n",
       "5133  2018-2-22        55       50       45           55          0.02\n",
       "5134  2018-2-23        54       47       39           47          0.00\n",
       "5135  2018-2-24        57       48       39           63          0.00\n",
       "5136  2018-2-25        59       50       40           63          0.00\n",
       "5137  2018-2-26        54       50       45           65          0.19\n",
       "5138  2018-2-27        58       51       44           43          0.00\n",
       "5139  2018-2-28        56       49       41           71          0.16\n",
       "5140   2018-3-1        59       54       48           74          1.04\n",
       "5141   2018-3-2        56       51       45           65          0.18\n",
       "5142   2018-3-3        53       48       42           76          0.05\n",
       "5143   2018-3-4        55       48       40           67          0.00\n",
       "5144   2018-3-5        61       51       41           56          0.00\n",
       "5145   2018-3-6        65       55       45           53          0.00\n",
       "5146   2018-3-7        70       61       52           46          0.01\n",
       "5147   2018-3-8        65       58       50           78          0.01\n",
       "5148   2018-3-9        65       57       49           79          0.00\n",
       "5149  2018-3-10        57       53       49           87          0.00\n",
       "5150  2018-3-11        63       55       46           84          0.00\n",
       "\n",
       "[5151 rows x 6 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper function to get data from a given database\n",
    "\n",
    "def get_data_from_db(db_name, path, sql_cmd):\n",
    "        connection = sqlite3.connect(path+db_name)\n",
    "        cursor = connection.cursor()\n",
    "        connection.row_factory = lambda cursor, row: row[0]\n",
    "        c = connection.cursor()\n",
    "        data = c.execute(sql_cmd).fetchall()\n",
    "        connection.close()\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis computation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Create dictionary to hold all the correlation data\n",
    "airport_pairs_dict = {}\n",
    "column_names = ['Airport_pairs','highT_1','highT_3','highT_7',\\\n",
    "                'precip_1','precip_3','precip_7','dist','long_delta' ]\n",
    "for key in column_names: \n",
    "    airport_pairs_dict[key] = list()\n",
    "    \n",
    "    \n",
    "\n",
    "###Get airport codes from database\n",
    "sql_cmd = \"SELECT ICAO FROM airport_info\"\n",
    "airport_code = get_data_from_db(db_name,path, sql_cmd)\n",
    "\n",
    "\n",
    "\n",
    "##### temporary code to eliminate bad files in database ###\n",
    "bad_airport = np.array(['KIAH','KLGA','KMSY','KIND'])\n",
    "airport_code = np.asarray(airport_code)\n",
    "cuts = np.ones(shape=airport_code.shape, dtype=bool)\n",
    "bad_indx = np.where(airport_code == 'KIAH')#np.array([word for word in bad_airport]))\n",
    "cuts[bad_indx] = 0\n",
    "bad_indx = np.where(airport_code == 'KLGA')#[word for word in bad_airport])\n",
    "cuts[bad_indx] = 0\n",
    "bad_indx = np.where(airport_code == 'KMSY')#[word for word in bad_airport])\n",
    "cuts[bad_indx] = 0\n",
    "bad_indx = np.where(airport_code == 'KIND')#[word for word in bad_airport])\n",
    "cuts[bad_indx] = 0\n",
    "\n",
    "\n",
    "### calculate the correlations for all permutations of airports\n",
    "for combo in permutations(airport_code[cuts],2):\n",
    "    \n",
    "    \n",
    "    sql_cmd_highT_1 = \"SELECT high_temp FROM airport_weather where ICAO = \" + '\"' + str(combo[0] + '\"')\n",
    "    sql_cmd_highT_2 = \"SELECT high_temp FROM airport_weather where ICAO = \" + '\"' + str(combo[1] + '\"')\n",
    "    \n",
    "    sql_cmd_precip_1 = \"SELECT precipitation FROM airport_weather where ICAO = \" + '\"' + str(combo[0] + '\"')\n",
    "    sql_cmd_precip_2 = \"SELECT precipitation FROM airport_weather where ICAO = \" + '\"' + str(combo[1] + '\"')\n",
    "    \n",
    "    sql_cmd_lat_1 = \"SELECT latitude_deg FROM airport_info where ICAO = \" + '\"' + str(combo[0] + '\"')\n",
    "    sql_cmd_lat_2 = \"SELECT latitude_deg FROM airport_info where ICAO = \" + '\"' + str(combo[1] + '\"')\n",
    "    \n",
    "    sql_cmd_long_1 = \"SELECT longitude_deg FROM airport_info where ICAO = \" + '\"' + str(combo[0] + '\"')\n",
    "    sql_cmd_long_2 = \"SELECT longitude_deg FROM airport_info where ICAO = \" + '\"' + str(combo[1] + '\"')\n",
    "    \n",
    "\n",
    "    high_temp_1 = get_data_from_db(db_name,path,sql_cmd_highT_1)\n",
    "    high_temp_2 = get_data_from_db(db_name,path,sql_cmd_highT_2)\n",
    "    \n",
    "    precip_1 = get_data_from_db(db_name,path,sql_cmd_precip_1)\n",
    "    precip_2 = get_data_from_db(db_name,path,sql_cmd_precip_2)\n",
    "    \n",
    "    lat_1 = get_data_from_db(db_name,path,sql_cmd_lat_1)[0]\n",
    "    lat_2 = get_data_from_db(db_name,path,sql_cmd_lat_2)[0]\n",
    "    \n",
    "    long_1 = get_data_from_db(db_name,path,sql_cmd_long_1)[0]\n",
    "    long_2 = get_data_from_db(db_name,path,sql_cmd_long_2)[0]\n",
    "    \n",
    "    #when calculating correlations, shift one array by 1,3,and 7 days to get\n",
    "    #the 1,3, and 7 day correlations\n",
    "    one_highT_coeff   = np.corrcoef(high_temp_1[:-1],high_temp_2[1:])[0,1]\n",
    "    three_highT_coeff = np.corrcoef(high_temp_1[:-3],high_temp_2[3:])[0,1]\n",
    "    seven_highT_coeff = np.corrcoef(high_temp_1[:-7],high_temp_2[7:])[0,1]\n",
    "    \n",
    "    one_precip_coeff   = np.corrcoef(precip_1[:-1],precip_2[1:])[0,1]\n",
    "    three_precip_coeff = np.corrcoef(precip_1[:-3],precip_2[3:])[0,1]\n",
    "    seven_precip_coeff = np.corrcoef(precip_1[:-7],precip_2[7:])[0,1]\n",
    "    \n",
    "    long_delta = long_2-long_1 #difference in longitude\n",
    "    \n",
    "    distance = great_circle((lat_1,long_1),(lat_2,long_2)).miles #absolute distance between cities\n",
    "    \n",
    "    #append each value to our dictionary\n",
    "    airport_pairs_dict['Airport_pairs'].append(combo)\n",
    "    airport_pairs_dict['highT_1'].append(one_highT_coeff)\n",
    "    airport_pairs_dict['highT_3'].append(three_highT_coeff)\n",
    "    airport_pairs_dict['highT_7'].append(seven_highT_coeff)\n",
    "    airport_pairs_dict['precip_1'].append(one_precip_coeff)\n",
    "    airport_pairs_dict['precip_3'].append(three_precip_coeff)\n",
    "    airport_pairs_dict['precip_7'].append(seven_precip_coeff)\n",
    "    airport_pairs_dict['dist'].append(distance)\n",
    "    airport_pairs_dict['long_delta'].append(long_delta)\n",
    "    \n",
    "\n",
    "#turn data dictonary into pandas df, setting the city pair as the index\n",
    "pairs_df = pd.DataFrame.from_dict(airport_pairs_dict).set_index('Airport_pairs') \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pairs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-241e43041c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pairs_df' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_results(df):\n",
    "    x_val = ['long_delta','dist']\n",
    "    y_val = ['highT_1','highT_3','highT_7','precip_1','precip_3','precip_7']\n",
    "    \n",
    "    fig, ax = plt.subplots(1, len(x_val), figsize = (12, 3 * len(x_val)))\n",
    "    \n",
    "    for ii in range(len(x_val)):\n",
    "        for jj in range(len(y_val)):\n",
    "            \n",
    "            ax[ii].set_xlabel(x_val[ii])\n",
    "            ax[ii].set_ylabel('Correlation coefficien')\n",
    "            \n",
    "            df_sort = df.sort_values(by = y_val[jj], ascending=False)[:10]\n",
    "            \n",
    "            ax[ii].plot(df_sort[x_val[ii]], df_sort[y_val[jj]], '0', label = y_val[jj])\n",
    "            ax[ii].legend(loc = 'best')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "plot_results(pairs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('day_of_month', 0),\n",
       "             ('temp_high', 1),\n",
       "             ('temp_ave', 2),\n",
       "             ('temp_low', 3),\n",
       "             ('humidity_ave', 8),\n",
       "             ('precipitation', 19)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#the location and \n",
    "data_needed = OrderedDict({'day_of_month': 0, 'temp_high': 1, 'temp_ave': 2, 'temp_low': 3,\n",
    "                                    'humidity_ave': 8, 'precipitation': 19})\n",
    "data_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_range = get_date_range_to_query(date_start = '2006/3/3',date_end='today')\n",
    "len(data_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
