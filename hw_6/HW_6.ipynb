{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import feature, transform, measure,filters\n",
    "from skimage.io import imread\n",
    "from skimage.color import gray2rgb, rgb2gray\n",
    "from skimage.filters import threshold_otsu, frangi\n",
    "from skimage.segmentation import felzenszwalb\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "# pip install imutils\n",
    "\n",
    "#import imutils\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from glob import glob\n",
    "from time import time\n",
    "\n",
    "import pickle \n",
    "\n",
    "#Note, I am just ignoring warnings because I get many flags that are unnecesary. \n",
    "#I understand this is not good practice, but just for visual aesthetic of the \n",
    "#notebook I don't want them to print\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract features from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dumb_features(img):\n",
    "    \"\"\"\n",
    "    Get simple features such as the min,max,mean,etc of the r,g,b channels\n",
    "    \"\"\"\n",
    "    \n",
    "    ratios = []\n",
    "    correlations = []\n",
    "    max_norm = []\n",
    "    mean_std = []\n",
    "        \n",
    "    a = img[:,:,0]\n",
    "    b = img[:,:,1]\n",
    "    c = img[:,:,2]    \n",
    "        \n",
    "    for ii,jj in combinations([a,b,c],2):\n",
    "        ratios.append(np.mean(ii)/np.mean(jj))\n",
    "        corr = np.corrcoef(np.ndarray.flatten(ii),np.ndarray.flatten(jj))[0,1]\n",
    "        correlations.append(corr)\n",
    "    for ii in [a,b,c]:\n",
    "        max_norm.append(np.max(ii)/np.mean(ii))    \n",
    "        mean_std.append(np.mean(ii)/np.std(ii)) \n",
    "    maxes = np.array([np.sum(a),np.sum(b),np.sum(c)])\n",
    "    dominant_color = np.argmax(maxes)    \n",
    "\n",
    "    \n",
    "    return np.asarray(ratios + correlations + max_norm + mean_std +dominant_color)\n",
    "\n",
    "def get_smart_features(img):\n",
    "    \"\"\"\n",
    "    get \"smart\" features, using more advanced tools from skimage\n",
    "    \"\"\"\n",
    "    img_grey = rgb2gray(img)\n",
    "    #img_grey_rz = transform.resize(img_grey,(338,424))\n",
    "    #it seems resizing the images makes it worse, so I \n",
    "    #taking out the above line of code\n",
    "    img_grey_rz = img_grey\n",
    "    thresh = threshold_otsu(img_grey_rz)\n",
    "    binary_img = img_grey_rz > thresh\n",
    "    \n",
    "    \n",
    "    edginess = np.sum(feature.canny(img_grey_rz,sigma=3))\n",
    "    corners = feature.corner_harris(img_grey_rz).size\n",
    "    shape = np.mean(feature.shape_index(img_grey_rz))\n",
    "    blobbiness = (feature.blob_dog(img_grey_rz)).shape[0]\n",
    "    perimeter = measure.perimeter(binary_img)\n",
    "    peaks = (feature.peak_local_max(img_grey_rz)).size\n",
    "    \n",
    "    smart_features = [edginess,corners,shape,blobbiness,perimeter,peaks]\n",
    "    \n",
    "    for ii,jj in combinations(smart_features,2):\n",
    "        try:\n",
    "            smart_features.append(ii/jj)\n",
    "        except:\n",
    "            smart_features.append(0)\n",
    "        \n",
    "    return np.asarray(smart_features)\n",
    "\n",
    "\n",
    "def get_features(filename):\n",
    "    \"\"\"\n",
    "    Takes a filename and reads in corresponding image,\n",
    "    then called get_dumb_features() and get_smart_features()\n",
    "    to get the image features\n",
    "    \"\"\"\n",
    "\n",
    "    img = imread(filename)\n",
    "\n",
    "    if len(img.shape) != 3:\n",
    "        img = gray2rgb(img)\n",
    "    \n",
    "        \n",
    "    dumb_features = get_dumb_features(img)\n",
    "    smart_features = get_smart_features(img)\n",
    "    \n",
    "    smart_features[np.isnan(smart_features)] = 10000.0\n",
    "    smart_features[np.isinf(smart_features)] = 0.0\n",
    "    \n",
    "    \n",
    "    good_features = np.concatenate((dumb_features , smart_features))\n",
    "\n",
    "    \n",
    "    return good_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in all the images to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On directory: 50_categories/\n",
      "On directory: 50_categories/gorilla\n",
      "On directory: 50_categories/raccoon\n",
      "On directory: 50_categories/crab\n",
      "On directory: 50_categories/blimp\n",
      "On directory: 50_categories/snail\n",
      "On directory: 50_categories/airplanes\n",
      "On directory: 50_categories/dog\n",
      "On directory: 50_categories/dolphin\n",
      "On directory: 50_categories/goldfish\n",
      "On directory: 50_categories/giraffe\n",
      "On directory: 50_categories/bear\n",
      "On directory: 50_categories/killer-whale\n",
      "On directory: 50_categories/penguin\n",
      "On directory: 50_categories/zebra\n",
      "On directory: 50_categories/duck\n",
      "On directory: 50_categories/conch\n",
      "On directory: 50_categories/camel\n",
      "On directory: 50_categories/owl\n",
      "On directory: 50_categories/helicopter\n",
      "On directory: 50_categories/starfish\n",
      "On directory: 50_categories/saturn\n",
      "On directory: 50_categories/galaxy\n",
      "On directory: 50_categories/goat\n",
      "On directory: 50_categories/iguana\n",
      "On directory: 50_categories/elk\n",
      "On directory: 50_categories/hummingbird\n",
      "On directory: 50_categories/triceratops\n",
      "On directory: 50_categories/porcupine\n",
      "On directory: 50_categories/teddy-bear\n",
      "On directory: 50_categories/comet\n",
      "On directory: 50_categories/hot-air-balloon\n",
      "On directory: 50_categories/leopards\n",
      "On directory: 50_categories/toad\n",
      "On directory: 50_categories/mussels\n",
      "On directory: 50_categories/kangaroo\n",
      "On directory: 50_categories/speed-boat\n",
      "On directory: 50_categories/bat\n",
      "On directory: 50_categories/swan\n",
      "On directory: 50_categories/octopus\n",
      "On directory: 50_categories/frog\n",
      "On directory: 50_categories/cormorant\n",
      "On directory: 50_categories/unicorn\n",
      "On directory: 50_categories/horse\n",
      "On directory: 50_categories/skunk\n",
      "On directory: 50_categories/mars\n",
      "On directory: 50_categories/ostrich\n",
      "On directory: 50_categories/goose\n",
      "On directory: 50_categories/llama\n",
      "On directory: 50_categories/snake\n",
      "On directory: 50_categories/elephant\n"
     ]
    }
   ],
   "source": [
    "#path = '/Users/cwfink/Documents/School/UC_Berkeley/Classes/Spring_2018/AY250/HW/Fink_ay250_homework/hw_6/50_categories/'\n",
    "path = '50_categories/'\n",
    "\n",
    "\n",
    "img_list =[]\n",
    "\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    print('On directory: {}'.format(subdir))\n",
    "    for file in files:\n",
    "        if '.DS_Store' not in file:\n",
    "            img = imread(subdir+'/'+file)\n",
    "            img_list.append(img)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list=np.asarray(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now find the ave width and higth to rescale the images by\n",
    "h = []\n",
    "w = []\n",
    "for ii, im in enumerate(img_list):\n",
    "    if len(im.shape) == 3:\n",
    "        h.append(im.shape[0])\n",
    "        w.append(im.shape[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338.281472684\n",
      "424.582185273\n"
     ]
    }
   ],
   "source": [
    "### Strangly, it seems that the model does better if we don't resize the images. so I removed this feature from the code\n",
    "print(np.mean(h))\n",
    "print(np.mean(w))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over all files in folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/Users/cwfink/Documents/School/UC_Berkeley/Classes/Spring_2018/AY250/HW/Fink_ay250_homework/hw_6/50_categories/'\n",
    "\n",
    "def classify_training_images(path,lgc_Save = False):\n",
    "    #base_path = '50_categories/'\n",
    "    subdirs = glob(path + '*/')\n",
    "\n",
    "    X = [] \n",
    "    Y = []\n",
    "\n",
    "    num_process = 16\n",
    "    pool = Pool(processes=num_process)\n",
    "    start_time = time()\n",
    "    for ii, folder in enumerate(subdirs):\n",
    "\n",
    "        label = folder.split('/')[1]\n",
    "        print('Processing Files for: {}, On folder {} out of 50'.format(label,ii+1))\n",
    "\n",
    "        files = glob(folder+'*.jpg')\n",
    "        Features = pool.map(get_features,files)\n",
    "        X.append(np.vstack(Features))\n",
    "        Y.append(np.repeat(label,len(Features)))\n",
    "        #print(Features)\n",
    "    end_time = time()\n",
    "    print('time to complete: {} min'.format(round((end_time-start_time)*60),3))\n",
    "    pool.terminate()\n",
    "    del pool\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    Y = np.concatenate(Y)\n",
    "    \n",
    "    if lgc_Save:\n",
    "        np.save('X_data.npy', X)\n",
    "        np.save('Y_data.npy', Y)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to build ML random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X,Y,lgc_Save=False):\n",
    "    \"\"\"\n",
    "    Scales the X data, trains the model, saves it, and prints the accuracy\n",
    "    \"\"\"\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,stratify = Y, random_state=42)\n",
    "    #scale training data\n",
    "    X_scale = StandardScaler()\n",
    "    X_train = X_scale.fit_transform(X_train)\n",
    "    X_test = X_scale.transform(X_test)\n",
    "    #get a baseline \n",
    "    dummy_clf = DummyClassifier(strategy='prior')\n",
    "    dummy_clf.fit(X_train, Y_train)\n",
    "    baseline_score = dummy_clf.score(X_test, Y_test)\n",
    "    \n",
    "    clf_rand_forest = RandomForestClassifier(n_estimators=1000)\n",
    "    clf_rand_forest = RandomForestClassifier(class_weight='balanced',n_jobs=-1, random_state=42)\n",
    "    clf_rand_forest.fit(X_train, Y_train)\n",
    "    score = clf_rand_forest.score(X_test, Y_test)\n",
    "    \n",
    "    print('Baseline score: {:2f} '.format(baseline_score))\n",
    "    print('Model score: {:2f}'.format(score))\n",
    "    \n",
    "    cv_scores = cross_val_score(clf_rand_forest, X, Y, cv=5)\n",
    "    print(\"Accuracy from cross validation: {:2f} +/- {:2f}\".format(cv_scores.mean(), cv_scores.std() * 2))\n",
    "    \n",
    "    print('Feature importance: \\n{}'.format(clf_rand_forest.feature_importances_))\n",
    "    \n",
    "    if lgc_Save:\n",
    "        save_file = {'model' : clf_rand_forest,\n",
    "                     'Scaler' : X_scale}\n",
    "        with open('ML_model.pkl','wb') as file:\n",
    "            pickle.dump(save_file,file)\n",
    "    \n",
    "    return clf_rand_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to be used for the final classifier to test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_classifier(path, model = 'ML_model.pkl'):\n",
    "    \n",
    "    X_final = []\n",
    "    label = []\n",
    "    \n",
    "    with open(model, 'rb') as file:\n",
    "        ML_model = pickle.load(file)\n",
    "    model = ML_model['model']\n",
    "    X_scale = ML_model['Scaler']\n",
    "    \n",
    "    files = glob(path+'*.jpg')\n",
    "    \n",
    "    for ii, file in enumerate(files):\n",
    "        X_final.append(get_features(file))\n",
    "        label.append(file.split('/')[-1])\n",
    "        \n",
    "    X_final = np.asarray(X_final)\n",
    "    \n",
    "    X_final_scaled = X_scale.transform(X_final)\n",
    "    \n",
    "    prediction = model.predict(X_final_scaled)\n",
    "        \n",
    "    with open('final_predictions.txt', 'w') as file:    \n",
    "        file.write('{:15} {}'.format('filename','predicted_class'))\n",
    "        file.write('\\n------------------------------------------\\n')\n",
    "        for ii, p in enumerate(prediction):\n",
    "            file.write('\\n{:15} ==> {}\\n'.format(label[ii],p))\n",
    "            \n",
    "            \n",
    "    print('predictions have been saved')      \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model and test final clasifier functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Files for: gorilla, On folder 1 out of 50\n",
      "Processing Files for: raccoon, On folder 2 out of 50\n",
      "Processing Files for: crab, On folder 3 out of 50\n",
      "Processing Files for: blimp, On folder 4 out of 50\n",
      "Processing Files for: snail, On folder 5 out of 50\n",
      "Processing Files for: airplanes, On folder 6 out of 50\n",
      "Processing Files for: dog, On folder 7 out of 50\n",
      "Processing Files for: dolphin, On folder 8 out of 50\n",
      "Processing Files for: goldfish, On folder 9 out of 50\n",
      "Processing Files for: giraffe, On folder 10 out of 50\n",
      "Processing Files for: bear, On folder 11 out of 50\n",
      "Processing Files for: killer-whale, On folder 12 out of 50\n",
      "Processing Files for: penguin, On folder 13 out of 50\n",
      "Processing Files for: zebra, On folder 14 out of 50\n",
      "Processing Files for: duck, On folder 15 out of 50\n",
      "Processing Files for: conch, On folder 16 out of 50\n",
      "Processing Files for: camel, On folder 17 out of 50\n",
      "Processing Files for: owl, On folder 18 out of 50\n",
      "Processing Files for: helicopter, On folder 19 out of 50\n",
      "Processing Files for: starfish, On folder 20 out of 50\n",
      "Processing Files for: saturn, On folder 21 out of 50\n",
      "Processing Files for: galaxy, On folder 22 out of 50\n",
      "Processing Files for: goat, On folder 23 out of 50\n",
      "Processing Files for: iguana, On folder 24 out of 50\n",
      "Processing Files for: elk, On folder 25 out of 50\n",
      "Processing Files for: hummingbird, On folder 26 out of 50\n",
      "Processing Files for: triceratops, On folder 27 out of 50\n",
      "Processing Files for: porcupine, On folder 28 out of 50\n",
      "Processing Files for: teddy-bear, On folder 29 out of 50\n",
      "Processing Files for: comet, On folder 30 out of 50\n",
      "Processing Files for: hot-air-balloon, On folder 31 out of 50\n",
      "Processing Files for: leopards, On folder 32 out of 50\n",
      "Processing Files for: toad, On folder 33 out of 50\n",
      "Processing Files for: mussels, On folder 34 out of 50\n",
      "Processing Files for: kangaroo, On folder 35 out of 50\n",
      "Processing Files for: speed-boat, On folder 36 out of 50\n",
      "Processing Files for: bat, On folder 37 out of 50\n",
      "Processing Files for: swan, On folder 38 out of 50\n",
      "Processing Files for: octopus, On folder 39 out of 50\n",
      "Processing Files for: frog, On folder 40 out of 50\n",
      "Processing Files for: cormorant, On folder 41 out of 50\n",
      "Processing Files for: unicorn, On folder 42 out of 50\n",
      "Processing Files for: horse, On folder 43 out of 50\n",
      "Processing Files for: skunk, On folder 44 out of 50\n",
      "Processing Files for: mars, On folder 45 out of 50\n",
      "Processing Files for: ostrich, On folder 46 out of 50\n",
      "Processing Files for: goose, On folder 47 out of 50\n",
      "Processing Files for: llama, On folder 48 out of 50\n",
      "Processing Files for: snake, On folder 49 out of 50\n"
     ]
    }
   ],
   "source": [
    "#Classify the data and Build the model\n",
    "X,Y = classify_training_images(path = '50_categories/',lgc_Save=True)\n",
    "model = build_model(X,Y,lgc_Save=True)\n",
    "\n",
    "#Just to test that the final classifier is working as expected\n",
    "#path = '50_categories/bat/'\n",
    "#final_classifier(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: I wouldn't bet my life on the accuracy of this model...\n",
    "So it seems that the all the features have about the same importance, and the 'dumb' features seem to be weighted slighly higher. This may be because all my features may in fact be pretty dumb.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
