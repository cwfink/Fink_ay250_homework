{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction with the World Homework (#3)\n",
    "Python Computing for Data Science (c) J Bloom, UC Berkeley 2018\n",
    "\n",
    "Due Tuesday 2pm, Feb 20, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Monty: The Python Siri\n",
    "\n",
    "Let's make a Siri-like program (call it Monty!) with the following properties:\n",
    "   - record your voice command\n",
    "   - use a webservice to parse that sound file into text\n",
    "   - based on what the text, take three different types of actions:\n",
    "       - send an email to yourself\n",
    "       - do some math\n",
    "       - tell a joke\n",
    "\n",
    "So for example, if you say \"Monty: email me with subject hello and body goodbye\", it will email you with the appropriate subject and body. If you say \"Monty: tell me a joke\" then it will go to the web and find a joke and print it for you. If you say, \"Monty: calculate two times three\" it should response with printing the number 6.\n",
    "\n",
    "Hint: you can use speed-to-text apps like Houndify (or, e.g., Google Speech https://cloud.google.com/speech/) to return the text (but not do the actions). You'll need to sign up for a free API and then follow documentation instructions for using the service within Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate our namespace\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import wave\n",
    "#from houndify import * \n",
    "import monty_key\n",
    "\n",
    "import houndify #class provided by houndify in order to interface with thier speach to text engine\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We define a function to record audio, we are recycling code from lecture\n",
    "\n",
    "def record_audio(length_of_recording ,file_name='' ,path = '',sample_rate = 16000):\n",
    "    \"\"\"\n",
    "    Takes input: \n",
    "    \n",
    "    length_of_recording: the desired lenth in seconds of the recording\n",
    "    path: the path for the .wav file to be saved, if not specified, it will \n",
    "    be saved in the current directory\n",
    "    file_name: the name of the .wav file to be saved, if not specified, it will\n",
    "    be named \"new_wave.wav\"\n",
    "    \n",
    "    sample_rate: Must be either 8kHz or 16kHz. If not specified, defaults to 16kHz\n",
    "    \n",
    "    Records audio from the building mic with sample rate of 44.1kHz for user defined length of time\n",
    "    A .wav file is then \n",
    "    \"\"\"\n",
    "    \n",
    "    #Check if user gave path/file name, if not, then given defaults\n",
    "    if len(file_name) != 0:    \n",
    "        WAVE_OUTPUT_FILENAME = path + file_name + '.wav'        \n",
    "    else:\n",
    "        WAVE_OUTPUT_FILENAME = path + \"new_wave.wav\"\n",
    "        \n",
    "    chunk = 1024\n",
    "    #FORMAT = pyaudio.paInt32\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = sample_rate\n",
    "    RECORD_SECONDS = length_of_recording                \n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format = FORMAT,\n",
    "        channels = CHANNELS,\n",
    "        rate = RATE,\n",
    "        input = True,\n",
    "        frames_per_buffer = chunk)\n",
    "    all = []\n",
    "    for i in range(0, int(RATE / chunk * RECORD_SECONDS)):\n",
    "        data = stream.read(chunk)\n",
    "        all.append(data)\n",
    "    print(\"* done recording\")\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    data = b\"\".join(all)\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, \"wb\")\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "    \n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "data = record_audio(6, 'joke' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = 'houndify_python3_sdk_1.0.0/test_audio/whatistheweatherthere.wav'\n",
    "fname = 'joke.wav'\n",
    "CLIENT_ID = monty_key.Client_ID\n",
    "CLIENT_KEY = monty_key.Client_Key\n",
    "AUDIO_FILE = fname\n",
    "BUFFER_SIZE = 512\n",
    "\n",
    "#\n",
    "# Simplest HoundListener; just print out what we receive.\n",
    "# You can use these callbacks to interact with your UI.\n",
    "#\n",
    "class MyListener(houndify.HoundListener):\n",
    "  def onPartialTranscript(self, transcript):\n",
    "    #print(\"Partial transcript: \" + transcript)\n",
    "    yield\n",
    "  def onFinalResponse(self, response):\n",
    "    #print(\"Final response: \" + str(response))\n",
    "    yield\n",
    "  def onError(self, err):\n",
    "    #print(\"Error: \" + str(err))\n",
    "    yield\n",
    "\n",
    "\n",
    "client = houndify.StreamingHoundClient(CLIENT_ID, CLIENT_KEY, \"monty\")\n",
    "client.setLocation(37.388309, -121.973968)\n",
    "\n",
    "#checks to make sure the audio meets the correct criteria to use Houndify\n",
    "audio = wave.open(AUDIO_FILE)\n",
    "if audio.getsampwidth() != 2:\n",
    "  print(\"%s: wrong sample width (must be 16-bit)\" % fname)\n",
    "if audio.getframerate() != 8000 and audio.getframerate() != 16000:\n",
    "  print(\"%s: unsupported sampling frequency (must be either 8 or 16 khz)\" % fname)\n",
    "if audio.getnchannels() != 1:\n",
    "  print(\"%s: must be single channel (mono)\" % fname)\n",
    "\n",
    "client.setSampleRate(audio.getframerate())\n",
    "client.start(MyListener())\n",
    "\n",
    "while True:\n",
    "  samples = audio.readframes(BUFFER_SIZE)\n",
    "  if len(samples) == 0: break\n",
    "  if client.fill(samples): break\n",
    "  time.sleep(0.032) # simulate real-time so we can see the partial transcripts\n",
    "     \n",
    "result = client.finish() # returns either final response or error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scientists use root'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['AllResults'][0]['SpokenResponse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Write a program that identifies musical notes from sound (AIFF) files. \n",
    "\n",
    "  - Run it on the supplied sound files (12) and report your program’s results. \n",
    "  - Use the labeled sounds (4) to make sure it works correctly. The provided sound files contain 1-3 simultaneous notes from different organs.\n",
    "  - Save copies of any example plots to illustrate how your program works.\n",
    "  \n",
    "  https://piazza.com/berkeley/spring2018/ay250class13410/resources -> Homeworks -> hw3_sound_files.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: You’ll want to decompose the sound into a frequency power spectrum. Use a Fast Fourier Transform. Be care about “unpacking” the string hexcode into python data structures. The sound files use 32 bit data. Play around with what happens when you convert the string data to other integer sizes, or signed vs unsigned integers. Also, beware of harmonics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
